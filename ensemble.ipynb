{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: [    0     1     2 ..., 19996 19997 19998] OUT: [    8     9    12 ..., 19990 19995 19999]\n",
      "(13333,) (6667,)\n",
      "OUT1: [   0    2    3 ..., 6663 6664 6666] OUT2: [   1    4    6 ..., 6660 6662 6665]\n",
      "(4444,) (2223,)\n"
     ]
    }
   ],
   "source": [
    "# Split y\n",
    "y_train = np.loadtxt('training_data.txt', skiprows = 1)[:, 0]\n",
    "\n",
    "# split into in and out\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "in_index, out_index = list(kf.split(y_train))[0]\n",
    "print(\"IN:\", in_index, \"OUT:\", out_index)\n",
    "y_in, y_out = y_train[in_index], y_train[out_index]\n",
    "print(y_in.shape, y_out.shape)\n",
    "\n",
    "# split into out1 and out2\n",
    "out_index_1, out_index_2 = list(kf.split(y_out))[0]\n",
    "print(\"OUT1:\", out_index_1, \"OUT2:\", out_index_2)\n",
    "y_out_1, y_out_2 = y_out[out_index_1], y_out[out_index_2]\n",
    "print(y_out_1.shape, y_out_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load prediction files from different classifiers\n",
    "N_CLF = 3\n",
    "X_out1 = np.ndarray((4444, N_CLF))\n",
    "X_out2 = np.ndarray((2223, N_CLF))\n",
    "X_test = np.ndarray((10000, N_CLF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural net\n",
    "X_out1[:, 0] = np.loadtxt(\"out1_neuralnet.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "X_out2[:, 0] = np.loadtxt(\"out2_neuralnet.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "X_test[:, 0] = np.loadtxt(\"test_neuralnet.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "# Logistic\n",
    "# X_out1[:, 1] = np.loadtxt(\"out1_logic.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "# X_out2[:, 1] = np.loadtxt(\"out2_logic.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "# X_test[:, 1] = np.loadtxt(\"test_logic.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "# Gradient Boosting\n",
    "X_out1[:, 1] = np.loadtxt(\"out1_gdboosting.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "X_out2[:, 1] = np.loadtxt(\"out2_gdboosting.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "X_test[:, 1] = np.loadtxt(\"test_gdboosting.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "# Random Forest\n",
    "X_out1[:, 2] = np.loadtxt(\"out1_forest.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "X_out2[:, 2] = np.loadtxt(\"out2_forest.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "X_test[:, 2] = np.loadtxt(\"test_forest.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "# SVM\n",
    "# X_train[:, 3] = np.loadtxt(\"svm_train_1225.csv\", skiprows=1, delimiter=',')[:, 1]\n",
    "# X_test[:, 3] = np.loadtxt(\"svm_test_1225.csv\", skiprows=1, delimiter=',')[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "0.848334833483\n",
      "{'C': 0.004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on predictions\n",
    "tuned_parameters = {'C': [0.001, 0.004, 0.006, 0.01, 0.05]}\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', verbose=1)\n",
    "clf.fit(X_out1,y_out_1)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853351327036\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.004)\n",
    "clf.fit(X_out1, y_out_1)\n",
    "# clf.predict(X_out2)\n",
    "print(clf.score(X_out2, y_out_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89229366  0.63260869  0.63240789]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission_file(pred, filename):\n",
    "    super_threshold_indices = pred >= 0.5\n",
    "    pred.fill(0)\n",
    "    pred[super_threshold_indices] = 1\n",
    "\n",
    "    submission = [[i+1, int(pred[i])] for i in range(len(pred))]\n",
    "    submission.insert(0, ['Id','Prediction'])\n",
    "    with open(filename, 'w') as f:\n",
    "        for line in submission:\n",
    "            f.write(','.join(map(str, line)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "make_submission_file(pred, \"test_predictions_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the test file\n",
    "pred = clf.predict(X_test)\n",
    "super_threshold_indices = pred >= 0.5\n",
    "pred.fill(0)\n",
    "pred[super_threshold_indices] = 1\n",
    "\n",
    "submission = [[i+1, int(pred[i])] for i in range(len(pred))]\n",
    "submission.insert(0, ['Id','Prediction'])\n",
    "with open('ensemble_test_prediction.csv', 'w') as f:\n",
    "    for line in submission:\n",
    "        f.write(','.join(map(str, line)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667\n",
      "584\n",
      "313\n",
      "650\n",
      "1890\n",
      "1765\n"
     ]
    }
   ],
   "source": [
    "def mismatch(y1, y2):\n",
    "    return np.sum(np.not_equal(y1, y2))\n",
    "print(mismatch(pred, X_test[:, 0]))\n",
    "print(mismatch(pred, X_test[:, 1]))\n",
    "print(mismatch(pred, X_test[:, 2]))\n",
    "print(mismatch(pred, X_test[:, 3]))\n",
    "\n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "print(mismatch(train_pred, y_train))\n",
    "print(mismatch(X_train[:, 2], y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
