{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20000, 1000)\n",
      "y_train shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "# Load training text file\n",
    "Data_train = np.loadtxt('training_data.txt', skiprows = 1)\n",
    "X_train = Data_train[:, 1:]\n",
    "y_train = Data_train[:, 0]\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training data\n",
    "for i in range(len(X_train[0])):\n",
    "    col = X_train[:, i]\n",
    "    mean = np.mean(col)\n",
    "    std = np.std(col)\n",
    "    X_train[:, i] = (col - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_273 (Dense)            (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 115,301\n",
      "Trainable params: 115,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "# Build sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(1000,)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "# Output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "# Print a summary\n",
    "model.summary()\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/15\n",
      "16000/16000 [==============================] - 6s 350us/step - loss: 0.6999 - acc: 0.5344 - val_loss: 0.6197 - val_acc: 0.8075\n",
      "Epoch 2/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.5020 - acc: 0.7727 - val_loss: 0.3653 - val_acc: 0.8425\n",
      "Epoch 3/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.3651 - acc: 0.8472 - val_loss: 0.3522 - val_acc: 0.8515\n",
      "Epoch 4/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.3364 - acc: 0.8654 - val_loss: 0.3528 - val_acc: 0.8505\n",
      "Epoch 5/15\n",
      "16000/16000 [==============================] - 1s 54us/step - loss: 0.3257 - acc: 0.8684 - val_loss: 0.3534 - val_acc: 0.8515\n",
      "Epoch 6/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.3175 - acc: 0.8710 - val_loss: 0.3541 - val_acc: 0.8525\n",
      "Epoch 7/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.3097 - acc: 0.8732 - val_loss: 0.3543 - val_acc: 0.8510\n",
      "Epoch 8/15\n",
      "16000/16000 [==============================] - 1s 56us/step - loss: 0.3011 - acc: 0.8787 - val_loss: 0.3566 - val_acc: 0.8517\n",
      "Epoch 9/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.2933 - acc: 0.8816 - val_loss: 0.3545 - val_acc: 0.8540\n",
      "Epoch 10/15\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.2900 - acc: 0.8832 - val_loss: 0.3537 - val_acc: 0.8532\n",
      "Epoch 11/15\n",
      "16000/16000 [==============================] - 1s 57us/step - loss: 0.2878 - acc: 0.8807 - val_loss: 0.3569 - val_acc: 0.8532\n",
      "Epoch 12/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.2817 - acc: 0.8855 - val_loss: 0.3566 - val_acc: 0.8560\n",
      "Epoch 13/15\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.2739 - acc: 0.8899 - val_loss: 0.3574 - val_acc: 0.8553\n",
      "Epoch 14/15\n",
      "16000/16000 [==============================] - 1s 60us/step - loss: 0.2705 - acc: 0.8910 - val_loss: 0.3628 - val_acc: 0.8540\n",
      "Epoch 15/15\n",
      "16000/16000 [==============================] - 1s 64us/step - loss: 0.2674 - acc: 0.8921 - val_loss: 0.3613 - val_acc: 0.8548\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(X_train, y_train, batch_size=300, epochs=15, validation_split=0.2, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 1s 75us/step\n",
      "Training score: 0.238491754043\n",
      "Training accuracy: 0.91395\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "score = model.evaluate(X_train, y_train, verbose=1)\n",
    "print('Training score:', score[0])\n",
    "print('Training accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 5s 239us/step - loss: 0.4975 - acc: 0.7554\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 3s 147us/step - loss: 0.3345 - acc: 0.8587\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.3047 - acc: 0.8719\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.2840 - acc: 0.8825\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.2670 - acc: 0.8881\n"
     ]
    }
   ],
   "source": [
    "# Train on the entire training dataset\n",
    "model = Sequential()\n",
    "# Layers\n",
    "model.add(Dense(500, activation=\"tanh\", input_shape=(1000,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "# Fit\n",
    "fit = model.fit(X_train, y_train, batch_size=256, epochs=5, shuffle=True, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "X_test = np.loadtxt('test_data.txt', skiprows = 1)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "super_threshold_indices = pred >= 0.5\n",
    "pred.fill(0)\n",
    "pred[super_threshold_indices] = 1\n",
    "\n",
    "submission = [[i+1, int(pred[i])] for i in range(len(pred))]\n",
    "submission.insert(0, ['Id','Prediction'])\n",
    "with open('submission_neural_net.csv', 'w') as f:\n",
    "    for line in submission:\n",
    "        f.write(','.join(map(str, line)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
