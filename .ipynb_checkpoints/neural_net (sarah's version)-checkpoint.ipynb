{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20000, 1000)\n",
      "y_train shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "# Load training text file\n",
    "Data_train = np.loadtxt('training_data.txt', skiprows = 1)\n",
    "X_train = Data_train[:, 1:]\n",
    "y_train = Data_train[:, 0]\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "# Build sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(500, activation=\"tanh\", input_shape=(1000,)))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(100, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "# Print a summary\n",
    "model.summary()\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 326us/step - loss: 0.3987 - acc: 0.8209 - val_loss: 0.3543 - val_acc: 0.8522\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 270us/step - loss: 0.3267 - acc: 0.8568 - val_loss: 0.3499 - val_acc: 0.8488\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 261us/step - loss: 0.3038 - acc: 0.8658 - val_loss: 0.3541 - val_acc: 0.8420\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 255us/step - loss: 0.2796 - acc: 0.8789 - val_loss: 0.3589 - val_acc: 0.8462\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 262us/step - loss: 0.2556 - acc: 0.8911 - val_loss: 0.3591 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 260us/step - loss: 0.2265 - acc: 0.9076 - val_loss: 0.3817 - val_acc: 0.8442\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 272us/step - loss: 0.1979 - acc: 0.9239 - val_loss: 0.3886 - val_acc: 0.8343\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 5s 284us/step - loss: 0.1661 - acc: 0.9403 - val_loss: 0.4058 - val_acc: 0.8385\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 261us/step - loss: 0.1339 - acc: 0.9566 - val_loss: 0.4149 - val_acc: 0.8290\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.1067 - acc: 0.9704 - val_loss: 0.4490 - val_acc: 0.8303\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=0.2, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 3s 128us/step\n",
      "Test score: 0.11947226403430104\n",
      "Test accuracy: 0.96395\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "score = model.evaluate(X_train, y_train, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing different dropout values on one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 282us/step - loss: 0.4008 - acc: 0.8190 - val_loss: 0.3577 - val_acc: 0.8405\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 275us/step - loss: 0.3306 - acc: 0.8581 - val_loss: 0.3567 - val_acc: 0.8470\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 257us/step - loss: 0.3055 - acc: 0.8673 - val_loss: 0.3502 - val_acc: 0.8508\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.2837 - acc: 0.8752 - val_loss: 0.3570 - val_acc: 0.8505\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 242us/step - loss: 0.2602 - acc: 0.8885 - val_loss: 0.3593 - val_acc: 0.8488\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.2290 - acc: 0.9067 - val_loss: 0.3644 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.1964 - acc: 0.9265 - val_loss: 0.3718 - val_acc: 0.8492\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.1577 - acc: 0.9484 - val_loss: 0.3898 - val_acc: 0.8445\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 232us/step - loss: 0.1220 - acc: 0.9639 - val_loss: 0.4160 - val_acc: 0.8420\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 225us/step - loss: 0.0928 - acc: 0.9769 - val_loss: 0.4336 - val_acc: 0.8363\n",
      "20000/20000 [==============================] - 2s 122us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 298us/step - loss: 0.4026 - acc: 0.8165 - val_loss: 0.3583 - val_acc: 0.8452\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.3276 - acc: 0.8591 - val_loss: 0.3490 - val_acc: 0.8470\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.3070 - acc: 0.8661 - val_loss: 0.3512 - val_acc: 0.8502\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.2887 - acc: 0.8717 - val_loss: 0.3637 - val_acc: 0.8480\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 276us/step - loss: 0.2693 - acc: 0.8841 - val_loss: 0.3538 - val_acc: 0.8480\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 277us/step - loss: 0.2472 - acc: 0.8944 - val_loss: 0.3730 - val_acc: 0.8458\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.2209 - acc: 0.9106 - val_loss: 0.3777 - val_acc: 0.8438\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.1917 - acc: 0.9274 - val_loss: 0.3903 - val_acc: 0.8375\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 250us/step - loss: 0.1604 - acc: 0.9437 - val_loss: 0.4100 - val_acc: 0.8395\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.1322 - acc: 0.9577 - val_loss: 0.4179 - val_acc: 0.8347\n",
      "20000/20000 [==============================] - 3s 126us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 303us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.3575 - val_acc: 0.8420\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.3302 - acc: 0.8575 - val_loss: 0.3551 - val_acc: 0.8538\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.3086 - acc: 0.8646 - val_loss: 0.3506 - val_acc: 0.8535\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.2911 - acc: 0.8716 - val_loss: 0.3518 - val_acc: 0.8530\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 250us/step - loss: 0.2759 - acc: 0.8780 - val_loss: 0.3622 - val_acc: 0.8462\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.2531 - acc: 0.8924 - val_loss: 0.3608 - val_acc: 0.8515\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.2299 - acc: 0.9024 - val_loss: 0.3718 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.2029 - acc: 0.9197 - val_loss: 0.3779 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.1751 - acc: 0.9360 - val_loss: 0.3947 - val_acc: 0.8425\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 242us/step - loss: 0.1465 - acc: 0.9501 - val_loss: 0.4080 - val_acc: 0.8390\n",
      "20000/20000 [==============================] - 2s 119us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 292us/step - loss: 0.4054 - acc: 0.8175 - val_loss: 0.3544 - val_acc: 0.8490\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.3330 - acc: 0.8556 - val_loss: 0.3486 - val_acc: 0.8512\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.3141 - acc: 0.8618 - val_loss: 0.3545 - val_acc: 0.8465\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2949 - acc: 0.8708 - val_loss: 0.3509 - val_acc: 0.8492\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2793 - acc: 0.8782 - val_loss: 0.3536 - val_acc: 0.8498\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.2622 - acc: 0.8874 - val_loss: 0.3625 - val_acc: 0.8490\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.2408 - acc: 0.8964 - val_loss: 0.3696 - val_acc: 0.8435\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 245us/step - loss: 0.2191 - acc: 0.9119 - val_loss: 0.3800 - val_acc: 0.8430\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.1949 - acc: 0.9231 - val_loss: 0.3950 - val_acc: 0.8397\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.1688 - acc: 0.9374 - val_loss: 0.4110 - val_acc: 0.8387\n",
      "20000/20000 [==============================] - 2s 124us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 316us/step - loss: 0.4075 - acc: 0.8160 - val_loss: 0.3637 - val_acc: 0.8410\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.3372 - acc: 0.8527 - val_loss: 0.3549 - val_acc: 0.8490\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 250us/step - loss: 0.3172 - acc: 0.8609 - val_loss: 0.3506 - val_acc: 0.8542\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.3031 - acc: 0.8678 - val_loss: 0.3500 - val_acc: 0.8530\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.2898 - acc: 0.8743 - val_loss: 0.3530 - val_acc: 0.8515\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.2781 - acc: 0.8791 - val_loss: 0.3555 - val_acc: 0.8508\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 269us/step - loss: 0.2618 - acc: 0.8862 - val_loss: 0.3589 - val_acc: 0.8520\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 5s 298us/step - loss: 0.2463 - acc: 0.8950 - val_loss: 0.3687 - val_acc: 0.8468\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 5s 284us/step - loss: 0.2274 - acc: 0.9032 - val_loss: 0.3714 - val_acc: 0.8452\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 5s 308us/step - loss: 0.2092 - acc: 0.9132 - val_loss: 0.3969 - val_acc: 0.8417\n",
      "20000/20000 [==============================] - 3s 141us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 6s 355us/step - loss: 0.4124 - acc: 0.8089 - val_loss: 0.3458 - val_acc: 0.8540\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 5s 291us/step - loss: 0.3397 - acc: 0.8533 - val_loss: 0.3559 - val_acc: 0.8470\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 273us/step - loss: 0.3241 - acc: 0.8589 - val_loss: 0.3506 - val_acc: 0.8508\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 262us/step - loss: 0.3129 - acc: 0.8626 - val_loss: 0.3485 - val_acc: 0.8525\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 267us/step - loss: 0.2975 - acc: 0.8690 - val_loss: 0.3503 - val_acc: 0.8478\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 265us/step - loss: 0.2881 - acc: 0.8746 - val_loss: 0.3564 - val_acc: 0.8535\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 277us/step - loss: 0.2805 - acc: 0.8772 - val_loss: 0.3598 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 266us/step - loss: 0.2679 - acc: 0.8806 - val_loss: 0.3679 - val_acc: 0.8510\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 274us/step - loss: 0.2551 - acc: 0.8899 - val_loss: 0.3789 - val_acc: 0.8498\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 257us/step - loss: 0.2461 - acc: 0.8939 - val_loss: 0.3765 - val_acc: 0.8482\n",
      "20000/20000 [==============================] - 3s 133us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 343us/step - loss: 0.4243 - acc: 0.8029 - val_loss: 0.3533 - val_acc: 0.8490\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 5s 308us/step - loss: 0.3472 - acc: 0.8496 - val_loss: 0.3492 - val_acc: 0.8465\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 273us/step - loss: 0.3267 - acc: 0.8598 - val_loss: 0.3467 - val_acc: 0.8502\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 5s 285us/step - loss: 0.3178 - acc: 0.8617 - val_loss: 0.3452 - val_acc: 0.8542\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 276us/step - loss: 0.3066 - acc: 0.8683 - val_loss: 0.3460 - val_acc: 0.8532\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 275us/step - loss: 0.2972 - acc: 0.8699 - val_loss: 0.3507 - val_acc: 0.8520\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 259us/step - loss: 0.2898 - acc: 0.8706 - val_loss: 0.3514 - val_acc: 0.8498\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 268us/step - loss: 0.2788 - acc: 0.8772 - val_loss: 0.3658 - val_acc: 0.8542\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2734 - acc: 0.8795 - val_loss: 0.3606 - val_acc: 0.8482\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.2645 - acc: 0.8850 - val_loss: 0.3703 - val_acc: 0.8452\n",
      "20000/20000 [==============================] - 3s 128us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 313us/step - loss: 0.4398 - acc: 0.7938 - val_loss: 0.3563 - val_acc: 0.8482\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 271us/step - loss: 0.3533 - acc: 0.8436 - val_loss: 0.3537 - val_acc: 0.8542\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 277us/step - loss: 0.3389 - acc: 0.8510 - val_loss: 0.3456 - val_acc: 0.8542\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.3206 - acc: 0.8606 - val_loss: 0.3495 - val_acc: 0.8520\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.3149 - acc: 0.8626 - val_loss: 0.3480 - val_acc: 0.8552\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 257us/step - loss: 0.3106 - acc: 0.8644 - val_loss: 0.3466 - val_acc: 0.8508\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 5s 299us/step - loss: 0.2997 - acc: 0.8678 - val_loss: 0.3501 - val_acc: 0.8578\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 278us/step - loss: 0.2963 - acc: 0.8714 - val_loss: 0.3523 - val_acc: 0.8520\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 263us/step - loss: 0.2886 - acc: 0.8726 - val_loss: 0.3570 - val_acc: 0.8538\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 255us/step - loss: 0.2857 - acc: 0.8739 - val_loss: 0.3563 - val_acc: 0.8540\n",
      "20000/20000 [==============================] - 3s 130us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 339us/step - loss: 0.4606 - acc: 0.7776 - val_loss: 0.3542 - val_acc: 0.8492\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 264us/step - loss: 0.3692 - acc: 0.8379 - val_loss: 0.3511 - val_acc: 0.8490\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 271us/step - loss: 0.3468 - acc: 0.8464 - val_loss: 0.3472 - val_acc: 0.8518\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 277us/step - loss: 0.3321 - acc: 0.8548 - val_loss: 0.3476 - val_acc: 0.8552\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 268us/step - loss: 0.3276 - acc: 0.8550 - val_loss: 0.3480 - val_acc: 0.8535\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 5s 296us/step - loss: 0.3183 - acc: 0.8618 - val_loss: 0.3561 - val_acc: 0.8548\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 267us/step - loss: 0.3146 - acc: 0.8628 - val_loss: 0.3502 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.3084 - acc: 0.8639 - val_loss: 0.3511 - val_acc: 0.8538\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.3070 - acc: 0.8686 - val_loss: 0.3497 - val_acc: 0.8540\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.3037 - acc: 0.8666 - val_loss: 0.3467 - val_acc: 0.8538\n",
      "20000/20000 [==============================] - 3s 131us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 550,701\n",
      "Trainable params: 550,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 5s 337us/step - loss: 0.5187 - acc: 0.7361 - val_loss: 0.3685 - val_acc: 0.8420\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.4017 - acc: 0.8196 - val_loss: 0.3568 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.3741 - acc: 0.8326 - val_loss: 0.3542 - val_acc: 0.8578\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.3578 - acc: 0.8444 - val_loss: 0.3533 - val_acc: 0.8562\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.3484 - acc: 0.8491 - val_loss: 0.3564 - val_acc: 0.8552\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.3412 - acc: 0.8512 - val_loss: 0.3607 - val_acc: 0.8560\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.3313 - acc: 0.8576 - val_loss: 0.3631 - val_acc: 0.8552\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 276us/step - loss: 0.3293 - acc: 0.8575 - val_loss: 0.3650 - val_acc: 0.8575\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 265us/step - loss: 0.3231 - acc: 0.8616 - val_loss: 0.3567 - val_acc: 0.8558\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 263us/step - loss: 0.3225 - acc: 0.8612 - val_loss: 0.3659 - val_acc: 0.8585\n",
      "20000/20000 [==============================] - 3s 161us/step\n"
     ]
    }
   ],
   "source": [
    "scores = [0]*10\n",
    "accuracy = [0]*10\n",
    "for i in range(10):\n",
    "    # Build sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hidden layers\n",
    "    model.add(Dense(500, activation=\"tanh\", input_shape=(1000,)))\n",
    "    model.add(Dropout(0.1 * i))\n",
    "    model.add(Dense(100, activation=\"tanh\"))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # Print a summary\n",
    "    model.summary()\n",
    "    # Compile\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    fit = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=0.2, shuffle=True, verbose=1)\n",
    "    score = model.evaluate(X_train, y_train, verbose=1)\n",
    "    scores[i] = score[0]\n",
    "    accuracy[i] = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f48fd26198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arange = np.multiply(range(10), .1)\n",
    "plt.plot(arange,scores, label = 'test score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhb6ISAj5/6FGaXyoGIkLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f48be594e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(arange,accuracy, label = 'test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = [0]*10\n",
    "accuracy = [0]*10\n",
    "for i in range(10):\n",
    "    # Build sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hidden layers\n",
    "    model.add(Dense(500, activation=\"tanh\", input_shape=(1000,)))\n",
    "    model.add(Dropout(0.025 * i))\n",
    "    model.add(Dense(100, activation=\"tanh\"))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # Print a summary\n",
    "    model.summary()\n",
    "    # Compile\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    fit = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=0.2, shuffle=True, verbose=1)\n",
    "    score = model.evaluate(X_train, y_train, verbose=1)\n",
    "    scores[i] = score[0]\n",
    "    accuracy[i] = score[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
